#!/usr/bin/env python3
"""Generate aggregate report from all eval JSON logs."""

import json
import os
import sys
from collections import defaultdict
from datetime import datetime


def load_runs(log_dir: str) -> list[dict]:
    """Load all JSON run files from the log directory."""
    runs = []
    for fname in os.listdir(log_dir):
        if not fname.endswith(".json"):
            continue
        path = os.path.join(log_dir, fname)
        try:
            with open(path) as f:
                data = json.load(f)
            # Must have required fields
            if "model" in data and "mode" in data and "total_tokens" in data:
                data["_file"] = fname
                runs.append(data)
        except (json.JSONDecodeError, KeyError):
            continue
    return runs


def model_label(model: str) -> str:
    """Extract a short label from a model name like openrouter/google/gemini-2.5-flash."""
    # Strip openrouter/ prefix and provider, keep the model name
    parts = model.split("/")
    return parts[-1] if parts else model


def pretty_label(label: str) -> str:
    """Make model labels more readable."""
    return label.replace("-", " ").replace("_", " ").title()


def group_runs(runs):
    """Group runs by (label, mode) and return grouped dict, labels, and modes."""
    grouped = defaultdict(list)
    for r in runs:
        label = r.get("label", model_label(r["model"]))
        grouped[(label, r["mode"])].append(r)
    all_labels = sorted(set(label for label, _ in grouped))
    modes = ["bash", "mcp"]
    return grouped, all_labels, modes


def generate_report(log_dir: str):
    runs = load_runs(log_dir)
    if not runs:
        print("No eval runs found.")
        return runs, None, None, None

    grouped, all_labels, modes = group_runs(runs)
    rows, leaderboard = compute_stats(grouped, all_labels, modes)

    # Print header
    print()
    print("=" * 100)
    print("  EVALUATION REPORT")
    print("=" * 100)
    print()

    # Per-mode table
    header = (
        f"  {'Model':<28} {'Mode':<6} {'Runs':>4} {'Wins':>4} {'Win%':>5}"
        f" {'Avg Tok':>8} {'Min Tok':>8} {'Max Tok':>8} {'Avg Turns':>10}"
    )
    print(header)
    print("  " + "-" * (len(header) - 2))

    for r in rows:
        print(
            f"  {r['label']:<28} {r['mode']:<6} {r['n']:>4} {r['wins']:>4} {r['win_pct']:>4.0f}%"
            f" {r['avg_tok']:>8.0f} {r['min_tok']:>8} {r['max_tok']:>8} {r['avg_turns']:>10.1f}"
        )
        # blank line between models
        if r['mode'] == modes[-1] or (r['mode'] != modes[-1] and (r['label'], modes[-1]) not in grouped):
            print()

    # Summary stats
    total_runs = len(runs)
    total_wins = sum(1 for r in runs if r["won"])
    total_tokens = sum(r["total_tokens"] for r in runs)
    print("  " + "-" * (len(header) - 2))
    print(f"  Total runs: {total_runs}   Total wins: {total_wins}   Total tokens: {total_tokens:,}")

    # Leaderboard
    print()
    print("  LEADERBOARD (avg tokens to win, winners only)")
    print("  " + "-" * 50)

    for i, (avg, label, mode, n) in enumerate(leaderboard, 1):
        print(f"  {i}. {label:<28} {mode:<6} {avg:>8.0f} avg tokens  ({n} wins)")

    print()

    return runs, grouped, all_labels, modes


def compute_stats(grouped, all_labels, modes):
    """Compute per-model stats and leaderboard from grouped runs."""
    rows = []
    for label in all_labels:
        for mode in modes:
            key = (label, mode)
            if key not in grouped:
                continue
            entries = grouped[key]
            n = len(entries)
            wins = sum(1 for e in entries if e["won"])
            win_pct = (wins / n * 100) if n else 0
            tokens = [e["total_tokens"] for e in entries]
            avg_tok = sum(tokens) / n
            min_tok = min(tokens)
            max_tok = max(tokens)
            turns = [e["turns"] for e in entries]
            avg_turns = sum(turns) / n
            rows.append({
                "label": label, "mode": mode, "n": n, "wins": wins,
                "win_pct": win_pct, "avg_tok": avg_tok, "min_tok": min_tok,
                "max_tok": max_tok, "avg_turns": avg_turns,
            })

    leaderboard = []
    for (label, mode), entries in grouped.items():
        winners = [e for e in entries if e["won"]]
        if not winners:
            continue
        avg = sum(e["total_tokens"] for e in winners) / len(winners)
        leaderboard.append((avg, label, mode, len(winners)))
    leaderboard.sort()

    return rows, leaderboard


def generate_dashboard(runs, grouped, all_labels, modes, project_root: str):
    """Write dashboard.md to the project root."""
    rows, leaderboard = compute_stats(grouped, all_labels, modes)
    total_runs = len(runs)
    total_wins = sum(1 for r in runs if r["won"])

    lines = []
    lines.append("# Evaluation Dashboard")
    lines.append("")
    lines.append(f"> Auto-generated by `eval/report.py` â€” {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    lines.append("")

    # Summary
    lines.append(f"**{total_runs}** total runs | **{total_wins}** wins | **{total_runs - total_wins}** failures")
    lines.append("")

    # Leaderboard
    lines.append("## Leaderboard")
    lines.append("")
    lines.append("Ranked by avg tokens to win (lower is better, winners only).")
    lines.append("")
    lines.append("| Rank | Model | Mode | Avg Tokens | Wins |")
    lines.append("|------|-------|------|-----------|------|")
    for i, (avg, label, mode, n) in enumerate(leaderboard, 1):
        lines.append(f"| {i} | {label} | {mode} | {avg:,.0f} | {n} |")
    lines.append("")

    # Full results table
    lines.append("## Full Results")
    lines.append("")
    lines.append("| Model | Mode | Runs | Wins | Win% | Avg Tokens | Min Tokens | Max Tokens | Avg Turns |")
    lines.append("|-------|------|------|------|------|-----------|-----------|-----------|-----------|")
    for r in rows:
        lines.append(
            f"| {r['label']} | {r['mode']} | {r['n']} | {r['wins']} | {r['win_pct']:.0f}%"
            f" | {r['avg_tok']:,.0f} | {r['min_tok']:,} | {r['max_tok']:,} | {r['avg_turns']:.1f} |"
        )
    lines.append("")

    path = os.path.join(project_root, "dashboard.md")
    with open(path, "w") as f:
        f.write("\n".join(lines))
    print(f"  Dashboard written to {path}")


def main():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    log_dir = sys.argv[1] if len(sys.argv) > 1 else os.path.join(script_dir, "logs")

    if not os.path.isdir(log_dir):
        print(f"ERROR: Log directory not found: {log_dir}")
        sys.exit(1)

    runs, grouped, all_labels, modes = generate_report(log_dir)
    if runs:
        generate_dashboard(runs, grouped, all_labels, modes, project_root)


if __name__ == "__main__":
    main()
